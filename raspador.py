# -*- coding: utf-8 -*-
"""CLIPPING ELEIÇÕES NA BAHIA_PROJETO_FINAL_MJD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t6JiMhYo6UKz1eO0JkoZcmuy9DGXSMAO

# **BIBLIOTECAS**
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import datetime
import bs4 
import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.base import MIMEBase
from email import encoders
import os
from dotenv import load_dotenv 
load_dotenv() 

"""#**DEFININDO TERMO DE BUSCA**"""

entrada = "petrobras" #input('Escreva aqui o termo de busca: ')

"""# **CORREIO** **24H**

"""

requisicao=requests.get('https://www.correio24horas.com.br/pesquisar?query='+ entrada)

html=requisicao.content

sopa=BeautifulSoup(html)

clipping_correio=sopa.findAll('article', {'class':'box box--lista box--neutro box--imagem'})

clipping_correio

link= clipping_correio[0].find('a').get('href')

link

titulos=sopa.find_all('div', {'class': 'titulo'})

lista_titulos = []

for titulo in titulos:
  lista_titulos.append(titulo.text.strip('...'))

lista_titulos

titulo

manchetes_link=[]
for noticia, titulo in zip(clipping_correio, titulos):
  link=noticia.find('a').get('href')
  titulo_= titulo .text.strip('...')
  manchetes_link.append([titulo_, link])

manchetes_link

correio=pd.DataFrame(manchetes_link, columns=['Título','Link'])

#correio['data']=datetime.datetime.now()
correio['veículo']='CORREIO'
#correio['data']=datetime.datetime.now()

correio

"""# **A** **TARDE**"""

requisicao=requests.get('https://atarde.com.br/?d=1&q=' + entrada)

html=requisicao.content

sopa=BeautifulSoup(html)

clipping_atarde=sopa.findAll('a', {'class':'mw-link-decoration'})

clipping_atarde

lista_link = []
for link in clipping_atarde:
  if link.img:
    link_ = 'https://atarde.com.br/' + link['href']
    titulo = link.img['alt'].strip('Imagem ilustrativa da imagem')
    lista_link.append([titulo, link_])

lista_link

atarde=pd.DataFrame(lista_link, columns=['Título','Link'])

#atarde['data']=datetime.datetime.now()
atarde['veículo']='A TARDE'
#atarde['data']=datetime.datetime.now()

atarde

"""# **IBAHIA**"""

requisicao=requests.get('https://www.ibahia.com/?q=' + entrada)

html=requisicao.content

sopa_ibahia=BeautifulSoup(html)

sopa_ibahia.prettify

clipping_ibahia=sopa_ibahia.findAll('article', {'class':'ib-chamadaHome'})

clipping_ibahia

lista_link = []

for link in clipping_ibahia:
  if link.img:
    link_ = 'https://www.ibahia.com/' + link.find('a').get('href')
    titulo = link.img['alt']
    lista_link.append([titulo, link_])

lista_link

ibahia=pd.DataFrame(lista_link, columns=['Título','Link',])

#ibahia['data']=datetime.datetime.now()
ibahia['veículo']='IBAHIA'
#ibahia['data']=datetime.datetime.now()

ibahia

"""#**BAHIA NOTÍCIAS**"""

requisicao=requests.get('https://www.bahianoticias.com.br/pesquisa/'+ entrada)

html=requisicao.content

sopa=BeautifulSoup(html)

clipping_bahianoticias=sopa.findAll('div', {'class':'sc-3c754a49-0 edpZTL'})

clipping_bahianoticias

link= clipping_bahianoticias[0].find('a').get('href')

('https://www.bahianoticias.com.br') + link

titulos=sopa.find_all('h3', {'class': 'sc-3c754a49-2 iihoil'})

lista_titulos = []

for titulo in titulos:
  lista_titulos.append(titulo.text.strip('...'))

lista_titulos

titulos

manchetes_link=[]
for noticia, titulo in zip(clipping_bahianoticias, titulos):
  link_ = 'https://www.bahianoticias.com.br' + noticia.find('a').get('href')
 # link=noticia.find('a').get('href')
  titulo_= titulo .text.strip('...')
  manchetes_link.append([titulo_, link_])

manchetes_link

bahia_noticias=pd.DataFrame(manchetes_link, columns=['Título','Link'])

#bahia_noticias['data']=datetime.datetime.now()
bahia_noticias['veículo']='BAHIA NOTÍCIAS'
#bahia_noticias['data']=datetime.datetime.now()

bahia_noticias

"""#**ACORDA CIDADE**"""

requisicao=requests.get('https://www.acordacidade.com.br/?s='+ entrada)

html=requisicao.content

sopa=BeautifulSoup(html)

clipping_acordacidade=sopa.findAll('a', {'class':'noticia-3 card-archive'})

clipping_acordacidade

#acordacidade(link)

lista_link = []
lista_titulos = []
for link in clipping_acordacidade:
    # Encontre o título dentro do link atual
    titulo = link.find('h2', {'class': 'txt-noticia title-20'})
    if titulo:
        # Adiciona apenas o texto do título, removendo espaços extras e reticências
        texto_titulo = titulo.get_text().strip()
        lista_titulos.append(texto_titulo)

        # Verifica se existe um atributo href no link
        if 'href' in link.attrs:
            link_ = link['href']
            # Aqui, mudamos para adicionar o texto do título e o link na lista_link
            lista_link.append([texto_titulo, link_])

lista_link

acorda_cidade=pd.DataFrame(lista_link, columns=['Título','Link'])

#acorda_cidade['data']=datetime.datetime.now()
acorda_cidade['veículo']='ACORDA CIDADE'
#acorda_cidade['data']=datetime.datetime.now()

acorda_cidade

"""# **DATA FRAME**"""

df_veiculos = pd.concat([correio, atarde, ibahia, bahia_noticias, acorda_cidade], ignore_index=True)

df_veiculos ['data']=datetime.datetime.now()

df_veiculos

dados_html = df_veiculos.to_html(index=False)

dados_html

"""#**ENVIANDO E-MAIL**"""

def enviar_email_com_html(html):
    smtp_server = "smtp-relay.brevo.com"
    port = 587
    email = "damascenarute@gmail.com"
    password = os.environ.get('CHAVE_EMAIL')
    remetente = "damascenarute@gmail.com"
    destinatario_email = ["anadirdamascena@gmail.com", "eduardovg2@insper.edu.br", "damascenarute@gmail.com"]


    msg = MIMEMultipart()
    msg['From'] = remetente
    msg['To'] = ", ".join(destinatario_email)
    msg['Subject'] = 'E-mail com Dados do Clipping'

    msg.attach(MIMEText(html, 'html'))

    with smtplib.SMTP(smtp_server, port) as server:
        server.starttls()
        server.login(email, password)
        server.sendmail(remetente, msg['To'], msg.as_string())

enviar_email_com_html(dados_html)